{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a124936",
   "metadata": {},
   "source": [
    "# Artificial intelligence and machine learning project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dbbc10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from pyampute.exploration.mcar_statistical_tests import MCARTest\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e473aa",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a9bc37b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Shared material/alien_galaxy.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dat \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mShared material/alien_galaxy.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdimensions of alien galaxy data is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdat\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(dat\u001b[38;5;241m.\u001b[39mdtypes)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Shared material/alien_galaxy.csv'"
     ]
    }
   ],
   "source": [
    "dat = pd.read_csv(\"Shared material/alien_galaxy.csv\")\n",
    "print(f'dimensions of alien galaxy data is {dat.shape}')\n",
    "print(dat.dtypes)\n",
    "dat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78c0f2c",
   "metadata": {},
   "source": [
    "### 1. Data cleaning\n",
    "From data head, few variables are observed as unnecessary, so we are dropping these variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ef6b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# droping unnecessary variables\n",
    "dat = dat.drop(['Colonization_Year', 'Planet_ID', 'Discovery_Date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db84d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting object type variables to check levels and frequencies\n",
    "obj_dat = dat.select_dtypes('object')\n",
    "print(f'Number of object types features are {obj_dat.shape[1]}')\n",
    "obj_dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0015806f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dat.describe(include=\"object\"))\n",
    "print(f'Frequency of each level of Dominant species social structure is \\n {dat[obj_dat.columns[0]].value_counts()}')\n",
    "print(f'Frequency of each level of Alien civilization level is \\n {dat[obj_dat.columns[1]].value_counts()}')\n",
    "#NOTE: The instances for which Dominant species social structure is ('Absurd', 'YOLO') will be dropped. ('Married', 'Together') will be merged as 'Married' \n",
    "# and ('Single', 'Alone') will be merged.\n",
    "# For instances of  Alien civilization level, where category are Basic will be merged as Graduation and 2n Cycle will be merged with Master. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7051c9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the relevant categories of Alien_Civilization_Level\n",
    "dat1 = dat\n",
    "dat1['Alien_Civilization_Level'] = dat1['Alien_Civilization_Level'].replace({'2n Cycle': 'Master', \n",
    "                                                                             'Basic' : 'Graduation'})\n",
    "dat1['Alien_Civilization_Level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a515b4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will remove instances with the two unknown categoies; Absurd and YOLO\n",
    "dat2 = dat1\n",
    "ind_dsss = dat2[(dat1['Dominant_Species_Social_Structure'] == 'Absurd') | \n",
    "               (dat1['Dominant_Species_Social_Structure'] == 'YOLO')].index\n",
    "dat2 = dat1.drop(index=ind_dsss)\n",
    "\n",
    "# merge the relevant categories of Dominant_Species_Social_Structure\n",
    "\n",
    "dat2['Dominant_Species_Social_Structure'] = dat1['Dominant_Species_Social_Structure'].replace({'Together': 'Married', \n",
    "                                                                                               'Alone': 'Single'})\n",
    "print(f'Dimension of data now is {dat1.shape}')\n",
    "dat2['Dominant_Species_Social_Structure'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ee8f2b",
   "metadata": {},
   "source": [
    "### 2. Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144b828e",
   "metadata": {},
   "source": [
    "#### Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30ee0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = np.transpose(dat2.describe())\n",
    "ss\n",
    "#NOTE: count column giving information about variation of mising values in each feature. \n",
    "#Most of the features has 0 as minimum, 25%, 50%, and 75% value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8407445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe of only numeric variables to make scatterplot matrix\n",
    "num_dat = dat.select_dtypes(\"float64\")\n",
    "print(f'number of numeric features are {num_dat.shape[1]}')\n",
    "num_dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658f0ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating scatter plot matric to observe how variables are inter-related.\n",
    "sns.set_theme(style='ticks')\n",
    "sns.pairplot(num_dat)\n",
    "#NOTE: few features such as Peace_Treaty_Accords, Cultural_Exchange_Programs, Cultural_Exchange_Programs, Military_Engagements, Inhabitants_Disputes, \n",
    "# Terraforming_Initiatives, Galactic_Trade_Revenue, Interstellar_Contact_Cost are identified to be explored further \n",
    "#(aim is to drop these features-- because of being approximately a constant in term of its values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe66058",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_dat['Peace_Treaty_Accords'].value_counts())\n",
    "print(num_dat['Technological_Advancements'].value_counts())\n",
    "print(num_dat['Cultural_Exchange_Programs'].value_counts())\n",
    "print(num_dat['Military_Engagements'].value_counts())\n",
    "print(num_dat['Inhabitants_Disputes'].value_counts())\n",
    "print(num_dat['Terraforming_Initiatives'].value_counts())\n",
    "#NOTE: Majority of planets has no peace treaty accords, technological advancements, cultural exchange programs, military engegements, \n",
    "# inhabitants dispute, and terraforming initiatives,\n",
    "print(num_dat['Galactic_Trade_Revenue'].value_counts()) #only one value planets\n",
    "print(num_dat['Interstellar_Contact_Cost'].value_counts()) #only one value for all planets\n",
    "#NOTE: drop these variables since these values are almost constant for all planets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda25c5e-fc1c-4489-bc3c-83d0505fed6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_dat.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3891022",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(num_dat.columns.tolist())\n",
    "\n",
    "num_dat = num_dat.drop(['Peace_Treaty_Accords', 'Technological_Advancements', 'Cultural_Exchange_Programs', \n",
    "                  'Military_Engagements', 'Inhabitants_Disputes', 'Terraforming_Initiatives', \n",
    "                  'Galactic_Trade_Revenue', 'Interstellar_Contact_Cost'], axis=1)\n",
    "num_dat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d165150f",
   "metadata": {},
   "source": [
    "#### Missing values plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48d71b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number and percentage of missing values according to columns\n",
    "{col: [dat2[col].isnull().sum(), f'% {np.round(np.mean(dat2[col].isnull()*100), 2)}'] \n",
    " for col in dat2.columns if dat2[col].isnull().any()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99a982f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dum1 = pd.get_dummies(dat2['Alien_Civilization_Level'], prefix='AlienCivilizationLevel' ,dtype= 'float64')\n",
    "dum2 = pd.get_dummies(dat2['Dominant_Species_Social_Structure'], prefix='DominantSpeciesSocialStructure' ,dtype= 'float64')\n",
    "dat3 = num_dat#pd.concat([num_dat, dum1, dum2], axis=1)\n",
    "dat3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92a7cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values plot\n",
    "sns.heatmap(dat.isnull())\n",
    "\n",
    "# check MCAR test to evaluate missing pattern in dataset\n",
    "mcarTest = MCARTest(method=\"little\")\n",
    "print(mcarTest.little_mcar_test(dat3))\n",
    "#NOTE: since p-value < 0.05, we can say that missing pattern of given dataset is missing completely at rondom.\n",
    "# Now, we can use any ML algorithim to impute the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf633af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing values based on KNN algorithm\n",
    "imputer = KNNImputer(n_neighbors= 5)\n",
    "dat_comp = imputer.fit_transform(dat3)\n",
    "#print(dat_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1267f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(pd.DataFrame(dat_comp, columns=dat3.columns).corr(), cmap='coolwarm')\n",
    "plt.title('Correlation plot')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b74d378",
   "metadata": {},
   "source": [
    "### 3) Machine learning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e9aab9",
   "metadata": {},
   "source": [
    "#### 3.1) Principal component analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b303aad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizing the data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = pd.DataFrame(scaler.fit_transform(dat_comp), columns= num_dat.columns)\n",
    "scaled_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca0fd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA visualization\n",
    "pca_dat = scaled_data\n",
    "pca_dat.index = dat1['Alien_Civilization_Level'].values\n",
    "pca_dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cecb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(pca_dat)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(pca_result[:, 0], pca_result[:, 1], alpha=0.5)\n",
    "plt.title(\"PCA of planets\")\n",
    "plt.xlabel(\"PCA 1\")\n",
    "plt.ylabel(\"PCA 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6056702c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataFrame of scores\n",
    "pca_scores = pd.DataFrame(pca_result, columns=['PC1', 'PC2'], index=pca_dat.index)\n",
    "\n",
    "# dataFrame of loadings\n",
    "loadings = pd.DataFrame(pca.components_.T,\n",
    "                        columns=['PC1', 'PC2'],\n",
    "                        index=pca_dat.columns)\n",
    "\n",
    "# PCA biplot\n",
    "plt.figure(figsize=(9, 7))\n",
    "sns.scatterplot(x='PC1', y='PC2', hue=pca_scores.index, data=pca_scores, palette='Set2', s=50)\n",
    "\n",
    "# Plot the loadings\n",
    "for i in range(loadings.shape[0]):\n",
    "    plt.arrow(0, 0, \n",
    "              loadings.PC1[i]*2, \n",
    "              loadings.PC2[i]*2, \n",
    "              color='black', alpha=0.6, head_width=0.05)\n",
    "    plt.text(loadings.PC1[i]*2.2, \n",
    "             loadings.PC2[i]*2.2, \n",
    "             loadings.index[i], \n",
    "             color='black', ha='center', va='center', fontsize=5)\n",
    "\n",
    "plt.xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)\")\n",
    "plt.ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)\")\n",
    "plt.title('PCA Biplot')\n",
    "plt.grid(True)\n",
    "plt.axhline(0, color='gray', linewidth=0.5)\n",
    "plt.axvline(0, color='gray', linewidth=0.5)\n",
    "plt.legend(title='Alien civilization level')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cb310f",
   "metadata": {},
   "source": [
    "#### 3.2) Kmeans clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366dfef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_dat = pca_dat \n",
    "\n",
    "# range of cluster values to test\n",
    "k_range = range(2, 11)\n",
    "inertias = []\n",
    "silhouettes = []\n",
    "\n",
    "# looping over different k values\n",
    "for k in k_range:\n",
    "    model = KMeans(n_clusters=k, random_state=42)\n",
    "    model.fit(kmeans_dat)\n",
    "    inertias.append(model.inertia_)\n",
    "    labels = model.labels_\n",
    "    silhouettes.append(silhouette_score(kmeans_dat, labels))\n",
    "\n",
    "# plot using elbow method\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(k_range, inertias, marker='o')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow method')\n",
    "\n",
    "# plot of silhouette scores\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(k_range, silhouettes, marker='o', color='green')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Silhouette score')\n",
    "plt.title('Silhouette analysis')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf9fd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kmeans with selected best k\n",
    "best_k = 3 \n",
    "final_kmeans = KMeans(n_clusters=best_k, random_state=42)\n",
    "kmeans_labels = final_kmeans.fit_predict(kmeans_dat)\n",
    "centroids = final_kmeans.cluster_centers_\n",
    "\n",
    "# PCA plotting with kmeans clusters\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(kmeans_dat)\n",
    "centroids_pca = pca.transform(centroids)\n",
    "\n",
    "pca_df0 = pd.DataFrame(pca_result, columns=['PC1', 'PC2'])\n",
    "pca_df0['Cluster'] = kmeans_labels\n",
    "pca_df0['Civilization_Level'] = kmeans_dat.index\n",
    "\n",
    "plt.figure(figsize=(9, 7))\n",
    "sns.scatterplot(data=pca_df0, x='PC1', y='PC2', hue='Cluster', style='Civilization_Level', palette='Set2', s=80, edgecolor='k')\n",
    "plt.scatter(centroids_pca[:, 0], centroids_pca[:, 1], s=100, c='black', marker='X', label='Centroids')\n",
    "plt.title('PCA projection with kmeans clusters')\n",
    "plt.xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)\")\n",
    "plt.ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)\")\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d968e8b2",
   "metadata": {},
   "source": [
    "#### 3.3) Agglomerative clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c3ca43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# range of cluster values to test\n",
    "k_range = range(2, 11)\n",
    "silhouettes = []\n",
    "\n",
    "# looping over different k values\n",
    "for k in k_range:\n",
    "    model = AgglomerativeClustering(n_clusters=k, linkage='ward')  # Ward as distance measure to minimize the variance of the clusters\n",
    "    labels = model.fit_predict(kmeans_dat)\n",
    "    silhouettes.append(silhouette_score(kmeans_dat, labels))\n",
    "\n",
    "# silhouette scores plot\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.plot(k_range, silhouettes, marker='o', color='blue')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Silhouette acore')\n",
    "plt.title('Silhouette analysis for agglomerative clustering')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f99792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agglomerative clustering with selected best k\n",
    "best_k = 3  \n",
    "final_agglomerative = AgglomerativeClustering(n_clusters=best_k, linkage='ward')\n",
    "agg_labels = final_agglomerative.fit_predict(kmeans_dat)\n",
    "\n",
    "# PCA plot with agglomerative clusters\n",
    "pca_df1 = pd.DataFrame(pca_result, columns=['PC1', 'PC2'])\n",
    "pca_df1['Cluster'] = agg_labels\n",
    "pca_df1['Civilization_Level'] = kmeans_dat.index\n",
    "\n",
    "plt.figure(figsize=(9, 7))\n",
    "sns.scatterplot(data=pca_df1, x='PC1', y='PC2', hue='Cluster', style='Civilization_Level', palette='Set2', s=80, edgecolor='k')\n",
    "plt.title('PCA projection with agglomerative clustering')\n",
    "plt.xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)\")\n",
    "plt.ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)\")\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b149c2c",
   "metadata": {},
   "source": [
    "#### 3.4) Gaussian Mixture Model (GMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6e6222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a GMM to the PCA result\n",
    "# test different k values for GMM by using BIC\n",
    "bic_scores = []\n",
    "k_range = range(1, 11) \n",
    "for k in k_range:\n",
    "    gmm = GaussianMixture(n_components=k, random_state=42)\n",
    "    gmm.fit(pca_result)\n",
    "    bic_scores.append(gmm.bic(pca_result))\n",
    "\n",
    "# BIC scores plot; to select the optimal number of clusters\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.plot(k_range, bic_scores, marker='o', color='blue')\n",
    "plt.title('BIC scores of Gaussian mixture model')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('BIC score')\n",
    "plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdf286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting best k based on BIC (lowest BIC)\n",
    "best_k = k_range[np.argmin(bic_scores)]\n",
    "\n",
    "# GMM with the best k\n",
    "final_gmm = GaussianMixture(n_components=best_k, random_state=42)\n",
    "gmm_labels = final_gmm.fit_predict(pca_result)\n",
    "\n",
    "# PCA plot with GMM cluster labels\n",
    "pca_df2 = pd.DataFrame(pca_result, columns=['PC1', 'PC2'])\n",
    "pca_df2['Cluster'] = gmm_labels\n",
    "\n",
    "plt.figure(figsize=(9, 7))\n",
    "sns.scatterplot(data=pca_df2, x='PC1', y='PC2', hue='Cluster', palette='Set2', s=80, edgecolor='k')\n",
    "plt.title(f'PCA with gaussian mixture model (GMM) - {best_k} Clusters')\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)')\n",
    "plt.legend(title='Cluster', loc='best')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f98883a",
   "metadata": {},
   "source": [
    "### 4) Evaluating model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3241f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Silhouette score\n",
    "kmeans_silhouette = silhouette_score(kmeans_dat, kmeans_labels)\n",
    "agg_silhouette = silhouette_score(kmeans_dat, agg_labels)\n",
    "gmm_silhouette = silhouette_score(kmeans_dat, gmm_labels)\n",
    "\n",
    "# 2) Calinski-Harabasz index\n",
    "kmeans_ch = calinski_harabasz_score(kmeans_dat, kmeans_labels)\n",
    "agg_ch = calinski_harabasz_score(kmeans_dat, agg_labels)\n",
    "gmm_ch = calinski_harabasz_score(kmeans_dat, gmm_labels)\n",
    "\n",
    "# 3) Davies-Bouldin index\n",
    "kmeans_db = davies_bouldin_score(kmeans_dat, kmeans_labels)\n",
    "agg_db = davies_bouldin_score(kmeans_dat, agg_labels)\n",
    "gmm_db = davies_bouldin_score(kmeans_dat, gmm_labels)\n",
    "\n",
    "\n",
    "results = {\n",
    "    'Kmeans': {\n",
    "        'Silhouette score': kmeans_silhouette,\n",
    "        'Calinski-Harabasz index': kmeans_ch,\n",
    "        'Davies-Bouldin index': kmeans_db\n",
    "    },\n",
    "    'Agglomerative clustering': {\n",
    "        'Silhouette score': agg_silhouette,\n",
    "        'Calinski-Harabasz index': agg_ch,\n",
    "        'Davies-Bouldin index': agg_db\n",
    "    },\n",
    "    'GMM': {\n",
    "        'Silhouette score': gmm_silhouette,\n",
    "        'Calinski-Harabasz index': gmm_ch,\n",
    "        'Davies-Bouldin index': gmm_db\n",
    "    }\n",
    "}\n",
    "comparison_df = pd.DataFrame(results)\n",
    "print(comparison_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdf883f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the clustering results\n",
    "def plot_clusters(dat, labels, title):\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_result = pca.fit_transform(dat)\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    sns.scatterplot(x=pca_result[:, 0], y=pca_result[:, 1], hue=labels, palette='Set3', s=60, edgecolor='k')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)')\n",
    "    plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)')\n",
    "    plt.legend(title='Cluster', loc='best')\n",
    "    plt.grid(True)\n",
    "\n",
    "plot_clusters(kmeans_dat, kmeans_labels, 'Kmeans clustering')\n",
    "plot_clusters(kmeans_dat, agg_labels, 'Agglomerative clustering')\n",
    "plot_clusters(kmeans_dat, gmm_labels, 'GMM clustering')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
